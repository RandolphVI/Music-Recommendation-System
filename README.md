# ALL WE NEED IS FFMÂ ğŸ™ƒ

This project is my project, and it is also a study of TensorFlow, Deep Learning(CNN, RNN, LSTM, etc.) and other Machine Learning things.

The main objective of the project is to predict the chances of a user listening to a song repetitively after the first observable listening event within a time window was triggered. If there are recurring listening event(s) triggered within a month after the userâ€™s very first observable listening event, its target is marked 1, and 0 otherwise in the training set. The same rule applies to the testing set.

## Requirements

- Python 3.x
- **Tensorflow 1.2.0 +**
- Numpy
- Gensim
- **GBDT**
- **Libffm**
- **g++ (with C++11 and OpenMP support)**

## Data

[Get the research data](https://www.kaggle.com/c/kkbox-music-recommendation-challenge)

æ•°æ®æ¥æºä¸º Kaggle ä¸Šçš„æ¯”èµ›æ•°æ®é›†ï¼Œå†…å®¹ä¸ºéŸ³ä¹æ¨èã€‚

## Overview



## GBDT



## LIBFFM

This most important model used in this solution is called **Field-aware Factorization Machines**. If you want to use this model, please download [LIBFFM](http://www.csie.ntu.edu.tw/~r01922136/libffm) first.



## How to Kick the Ass ğŸ‘¾

### Step 1: Exploratory Data Analysis(EDA)

#### åŸå§‹ç‰¹å¾

- ç”¨æˆ·ç‰¹å¾
  - `user_id(msno)`
  - `city`
  - `gender`
  - `bd`
- éŸ³ä¹ç‰¹å¾
  - `song_id`
  - `song_length`
  - `genre_ids`
  - `language`
  - `name`
  - `artist_name`
  - `composer`
  - `lyricist`
  - `isrc`
- äº¤äº’ç‰¹å¾
- ä¸Šä¸‹æ–‡ç‰¹å¾
  - `registered_via`
  - `registration_init_time`
  - `exipration_date`
  - `source_system_tab`
  - `source_screen_name`
  - `source_type`

### Step 2:  Feature Engineering

Feature Engineering æ˜¯æŠŠ raw data è½¬æ¢æˆ features çš„æ•´ä¸ªè¿‡ç¨‹çš„æ€»ç§°ã€‚åŸºæœ¬ä¸Šç‰¹å¾å·¥ç¨‹å°±æ˜¯ä¸ªæ‰‹è‰ºæ´»ï¼Œåˆ¶ä½œçš„å¥½åå…¨å‡­äººçš„åŠŸå¤«ï¼Œå¾€ç»†äº†è®²ï¼Œä¾¿æ˜¯åˆ›é€ åŠ›ä¸ç»éªŒã€‚

ä»¥æ¨èç³»ç»Ÿä¸ºä¾‹ï¼Œæ•°æ®é›†ä¸­çš„ç‰¹å¾å¯ä»¥åˆ†æˆä»¥ä¸‹å››ç§ï¼š

- ç”¨æˆ·ç‰¹å¾ï¼šç”¨æˆ·æœ¬èº«çš„å„ç§å±æ€§ï¼Œä¾‹å¦‚ user idã€æ€§åˆ«ã€æ‰€åœ¨çš„åŸå¸‚ç­‰
- éŸ³ä¹ç‰¹å¾ï¼šéŸ³ä¹æœ¬èº«çš„å„ç§å±æ€§ï¼Œä¾‹å¦‚ item idã€æ­Œæ›²åã€æ¼”å”±è€…ã€ä½œæ›²å®¶ã€ä½œè¯å®¶ã€éŸ³ä¹é£æ ¼åˆ†ç±»ç­‰
- äº¤äº’ç‰¹å¾ï¼šç”¨æˆ·å¯¹éŸ³ä¹åšå‡ºçš„æŸé¡¹è¡Œä¸ºï¼Œè¯¥è¡Œä¸ºçš„ aggregation æˆ–äº¤å‰ç‰¹å¾ï¼Œä¾‹å¦‚æœ€è¿‘å¬çš„æ­Œæ›²çš„æ›²é£åˆ†å¸ƒæˆ–å–œçˆ±çš„æ­Œæ‰‹çš„ç±»å‹
- ä¸Šä¸‹æ–‡ç‰¹å¾ï¼šç”¨æˆ¶å¯¹éŸ³ä¹åšå‡ºçš„æŸé¡¹è¡Œï¼Œè¯¥è¡Œä¸ºçš„ metadataï¼Œä¾‹å¦‚æ³¨å†Œçš„æ—¶é—´ã€ä½¿ç”¨çš„è®¾å¤‡ç­‰

æœ‰äº›ç‰¹å¾æ˜¯åœ¨èµ„æ–™ EDA é˜¶æ®µå°±å¯ä»¥æ‹¿åˆ°ï¼Œæœ‰äº›ç‰¹å¾åˆ™éœ€è¦é¢å¤–çš„æ­¥éª¤ï¼ˆä¾‹å¦‚å¦‚é€è¿‡å¤–éƒ¨çš„ API æˆ–è€…å…¶ä»–æ¨¡å‹ï¼‰æ‰èƒ½å–å¾—ã€‚

#### è”æƒ³ç‰¹å¾

- ç”¨æˆ·ç‰¹å¾

  - `user_days_between_registration_today`ï¼šè¯¥ç”¨æˆ·çš„æ³¨å†Œæ—¶é—´è·ç¦»ä»Šå¤©è¿‡äº†å‡ å¤©
  - `user_days_between_exipration_today`ï¼šè¯¥ç”¨æˆ·çš„é€€è®¢æ—¶é—´è·ç¦»ä»Šå¤©è¿‡äº†å‡ å¤©

- éŸ³ä¹ç‰¹å¾

  - `song_id`

- äº¤äº’ç‰¹å¾

- ä¸Šä¸‹æ–‡ç‰¹å¾

  - `als_model_prediction`ï¼šæ¥è‡ª ALS æ¨¡å‹çš„é¢„æµ‹å€¼ï¼Œè¯¥ç”¨æˆ·å¯¹æŸéŸ³ä¹çš„åå¥½ç¨‹åº¦

  - `gbdt_model_index`: æ¥è‡ª GBDT æ¨¡å‹çš„ tree indexï¼ŒæŸ observation çš„è‡ªåŠ¨ç‰¹å¾

#### Missing Value Imputation ç¼ºå¤±å€¼å¤„ç†

æœ€ç®€å•æš´åŠ›çš„åšæ³•å½“ç„¶å°±æ˜¯ç›´æ¥ drop æ‰é‚£äº›å«æœ‰ç¼ºå¤±å€¼çš„ rowsã€‚

- é’ˆå¯¹ numerical ç‰¹å¾çš„ç¼ºå¤±å€¼ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹æ–¹å¼å–ä»£ï¼š
  - 0ï¼Œç¼ºç‚¹æ˜¯å¯èƒ½ä¼šæ··æ·†å…¶ä»–æœ¬æ¥å°±æ˜¯ 0 çš„æ•°å€¼
  - -999ï¼Œç”¨æŸä¸ªæ­£å¸¸æƒ…å†µä¸‹ä¸ä¼šå‡ºç°çš„æ•°å€¼ä»£æ›¿ï¼Œä½†æ˜¯é€‰å¾—ä¸å¥½å¯èƒ½ä¼šå˜æˆå¼‚å¸¸å€¼ï¼Œè¦ç‰¹åˆ«å¯¹å¾…
  - Meanï¼Œå¹³å‡æ•°
  - Medianï¼Œä¸­ä½æ•°ï¼Œè·Ÿå¹³å‡æ•°ç›¸æ¯”ï¼Œä¸ä¼šè¢«å¼‚å¸¸å€¼å¹²æ‰°
- é’ˆå¯¹ categorical ç‰¹å¾çš„ç¼ºå¤±å€¼ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹æ–¹å¼å–ä»£ï¼š
  - Modeï¼Œä¼—æ•°ï¼Œæœ€å¸¸è§çš„å€¼
  - æ”¹æˆ "Others" ä¹‹ç±»çš„å€¼

å‡è®¾ä½ è¦å¡«è¡¥ age è¿™ä¸ªç‰¹å¾ï¼Œç„¶åä½ æœ‰å…¶ä»–ä¾‹å¦‚ gender è¿™æ ·çš„ç‰¹å¾ï¼Œä½ å¯ä»¥åˆ†åˆ«è®¡ç®—ç”·æ€§å’Œå¥³æ€§çš„ age çš„ meanã€median å’Œ mode æ¥å¡«è¡¥ç¼ºå¤±å€¼ï¼›æ›´å¤æ‚ä¸€ç‚¹çš„æ–¹å¼æ˜¯ï¼Œä½ å¯ä»¥æŠŠæ²¡æœ‰ç¼ºå¤±å€¼çš„æ•°æ®æŒ‘å‡ºæ¥ï¼Œç”¨å®ƒä»¬æ¥è®­ç»ƒä¸€ä¸ª regression æˆ– classification æ¨¡å‹ï¼Œç”¨è¿™ä¸ªæ¨¡å‹æ¥é¢„æµ‹ç¼ºå¤±å€¼ã€‚

ä¸è¿‡å…¶å®æœ‰äº›ç®—æ³•æ˜¯å¯ä»¥å®¹è®¸ç¼ºå¤±å€¼çš„ï¼Œè¿™æ—¶å€™å¯ä»¥æ–°å¢ä¸€ä¸ª has_missing_value æ ä½ï¼ˆç§°ä¸º NA indicator columnï¼‰ã€‚

#### Outliers Detection é‡ç‚¹å¤„ç†

å‘ç°ç¦»ç¾¤å€¼æœ€ç›´è§‚çš„æ–¹å¼å°±æ˜¯ç”»å›¾è¡¨ï¼Œé’ˆå¯¹å•ä¸€ç‰¹å¾å¯ä»¥ä½¿ç”¨ box plotï¼›ä¸¤ä¸¤ç‰¹å¾åˆ™å¯ä»¥ä½¿ç”¨ scatter plotã€‚

å¤„ç½®ç¦»ç¾¤å€¼çš„æ–¹å¼é€šå¸¸æ˜¯ç›´æ¥åˆ é™¤æˆ–æ˜¯åšå˜æ¢ï¼ˆä¾‹å¦‚ log transformation æˆ– binningï¼‰ï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥å¥—ç”¨å¤„ç†ç¼ºå¤±å€¼çš„æ–¹å¼ã€‚

#### Duplicate Entries Removal å¼‚å¸¸å€¼å¤„ç†

Duplicate æˆ– redundant å°¤å…¶æŒ‡çš„æ˜¯é‚£äº› features éƒ½ä¸€æ ·ï¼Œä½†æ˜¯ target variable å´ä¸åŒçš„æ•°æ®ã€‚

#### Feature Scaling ç‰¹å¾ç¼©æ”¾

- **Standardization æ ‡å‡†åŒ–**

åŸå§‹æ•°æ®é›†ä¸­ï¼Œå› ä¸ºå„ä¸ªç‰¹å¾çš„å«ä¹‰å’Œå•ä½ä¸åŒï¼Œæ¯ä¸ªç‰¹å¾çš„å–å€¼èŒƒå›´å¯èƒ½ä¼šå·®å¼‚å¾ˆå¤§ã€‚ä¾‹å¦‚æŸä¸ªäºŒå…ƒç‰¹å¾çš„èŒƒå›´æ˜¯ 0 æˆ– 1ï¼Œå¦ä¸€ä¸ªç‰¹å¾çš„èŒƒå›´å¯èƒ½æ˜¯ [0, 1000000]ï¼Œç”±äºå–å€¼èŒƒå›´ç›¸å·®è¿‡å¤§å¯¼è‡´äº†æ¨¡å‹å¯èƒ½ä¼šæ›´åå‘äºå–å€¼èŒƒå›´è¾ƒå¤§çš„é‚£ä¸ªç‰¹å¾ã€‚è§£å†³çš„åŠæ³•å°±æ˜¯æŠŠå„ç§ä¸åŒ scale çš„ç‰¹å¾è½¬æ¢æˆåŒæ ·çš„ scaleï¼Œç§°ä¸ºæ ‡å‡†åŒ–æˆ–æ­£è§„åŒ–ã€‚

ç‹­ä¹‰æ¥è¯´ï¼Œæ ‡å‡†åŒ–ä¸“é—¨æŒ‡çš„æ˜¯é€šè¿‡è®¡ç®— z-scoreï¼Œè®©æ•°æ®çš„ mean ä¸º 0ã€ variance ä¸º 1ã€‚

- **Normalization å½’ä¸€åŒ–**

å½’ä¸€åŒ–æ˜¯æŒ‡æŠŠæ¯ä¸ªæ ·æœ¬ç¼©æ”¾åˆ°å•ä½èŒƒæ•°ï¼ˆæ¯ä¸ªæ ·æœ¬çš„èŒƒæ•°ä¸º 1ï¼‰ï¼Œé€‚ç”¨äºè®¡ç®— dot product æˆ–è€…ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚é™¤äº†æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–ä¹‹å¤–ï¼Œå…¶ä»–è¿˜æœ‰é€šè¿‡æœ€å¤§ã€æœ€å°å€¼ï¼ŒæŠŠæ•°æ®çš„èŒƒå›´ç¼©æ”¾åˆ° [0, 1] æˆ– [-1, 1] çš„åŒºé—´ç¼©æ”¾æ³•ï¼Œä¸è¿‡è¿™ä¸ªæ–¹æ³•å®¹æ˜“å—å¼‚å¸¸å€¼çš„å½±å“ã€‚

æ ‡å‡†åŒ–æ˜¯åˆ†åˆ«å¯¹å•ä¸€ç‰¹å¾è¿›è¡Œï¼ˆé’ˆå¯¹ columnï¼‰ï¼›å½’ä¸€åŒ–æ˜¯å¯¹æ¯ä¸ª observation è¿›è¡Œï¼ˆé’ˆå¯¹ rowï¼‰ã€‚

**1. å¯¹ SVMã€logistic regression æˆ–å…¶ä»–ä½¿ç”¨ squared loss function çš„æ¼”ç®—æ³•æ¥è¯´ï¼Œéœ€è¦ standardizationï¼›**

**2. å¯¹ Vector Space Model æ¥è¯´ï¼Œéœ€è¦ normalizationï¼›**

**3. å¯¹ tree-based çš„ç®—æ³•ï¼ŒåŸºæœ¬ä¸Šéƒ½ä¸éœ€è¦æ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–ï¼Œå®ƒä»¬å¯¹ scale ä¸æ•æ„Ÿã€‚**

#### Feature Transformation ç‰¹å¾å˜æ¢

é’ˆå¯¹è¿ç»­å€¼ç‰¹å¾ï¼š

- **Rounding** 

  æŸäº›ç²¾åº¦æœ‰åˆ°å°æ•°ç‚¹åç¬¬ n ä½çš„ç‰¹å¾ï¼Œå¦‚æœä½ å…¶å®ä¸éœ€è¦é‚£ä¹ˆç²¾ç¡®ï¼Œå¯ä»¥è€ƒè™‘ `round(value * m)` æˆ– `round(log(value))` è¿™æ ·çš„åšæ³•ï¼Œç”šè‡³å¯ä»¥æŠŠ round ä¹‹åçš„æ•°å€¼å½“æˆ categorical ç‰¹å¾ã€‚

- **Log Transformation**

  å› ä¸º x è¶Šå¤§ï¼Œlog(x) å¢é•¿çš„é€Ÿåº¦å°±è¶Šæ…¢ï¼Œæ‰€ä»¥å– log çš„æ„ä¹‰æ˜¯å¯ä»¥ compress å¤§æ•°å’Œ expand å°æ•°ï¼Œæ¢å¥è¯è¯´å°±æ˜¯å‹ç¼© "long tail" å’Œå±•å¼€ "head"ã€‚å‡è®¾ x åŸæœ¬çš„èŒƒå›´æ˜¯ [100, 1000]ï¼Œlog(x, 10) ä¹‹åçš„èŒƒå›´å°±å˜æˆ [2, 3] äº†ã€‚ä¹Ÿå¸¸å¸¸ä½¿ç”¨ log(1 + x) æˆ– log(x / (1 - x))ã€‚

  å¦å¤–ä¸€ç§ç±»ä¼¼çš„åšæ³•æ˜¯ square root å¹³æ–¹æ ¹æˆ– cube root ç«‹æ–¹æ ¹ï¼ˆå¯ä»¥ç”¨åœ¨è´Ÿæ•°ï¼‰ã€‚

- â€‹

â€‹


æ•°æ®æ€»å…±æœ‰ 4 åˆ—æ•°å€¼ç‰¹å¾ï¼Œ15 åˆ—ç±»åˆ«ç‰¹å¾ï¼Œä½œè€…é¦–å…ˆå°†13åˆ—æ•°å€¼ç‰¹å¾ä¸26åˆ—ç±»åˆ«ç‰¹å¾(é€‰å–å‡ºç°çš„æ¯”ä¾‹éå¸¸é«˜çš„ä¸€äº›ç±»å‹ä½œä¸ºç‰¹å¾, ä½¿ç”¨one-hotè¿›è¡Œç¼–ç )æ”¾å…¥gbdtä¸­è®­ç»ƒ30æ£µé«˜åº¦å‡ä¸º7çš„æ ‘ï¼Œæ¯æ£µæ ‘ä½œä¸ºä¸€ä¸ªç‰¹å¾, å…±æœ‰30ä¸ªç‰¹å¾, ç‰¹å¾çš„å€¼æ˜¯æœ€åæ˜¾ç°å‡ºå€¼çš„å¶å­èŠ‚ç‚¹çš„åºå·, å³è¿™ä¸ªå€¼ä¸º0-255, ä½œè€…æœ€åå°†13+26+30ä¸€å…±69ä¸ªç‰¹å¾çš„æ ‡ç­¾ç»è¿‡hashå¤„ç†, ç„¶åä¸10^6å–æ¨¡åšä¸ºç‰¹å¾çš„ç´¢å¼•, å€¼ä»ç”¨åŸæ¥ç‰¹å¾çš„å€¼, è·å–åˆ°10^6ä¸ªone-hotç¼–ç åçš„ç¨€ç–ç‰¹å¾çŸ©é˜µ, æ”¾å…¥FFMæ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒ

## About Me

é»„å¨ï¼ŒRandolph

SCU SE Bachelor; USTC CS Master

Email: chinawolfman@hotmail.com

My Blog: [randolph.pro](http://randolph.pro)

LinkedIn: [randolph's linkedin](https://www.linkedin.com/in/randolph-%E9%BB%84%E5%A8%81/)

## Reference

- â€‹
- [Field-aware Factorization Machines for CTR Prediction](http://ntucsu.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf)
- [Field-aware Factorization Machines in a Real-world Online Advertising System](https://arxiv.org/pdf/1701.04099.pdf)
